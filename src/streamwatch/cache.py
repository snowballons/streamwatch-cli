"""
Stream status caching module for StreamWatch application.

This module provides caching functionality to improve performance by reducing
redundant streamlink calls for recently checked streams.
"""

import logging
import time
from dataclasses import dataclass, field
from threading import Lock
from typing import Dict, Optional, Set, Tuple

from . import config
from .models import StreamStatus

logger = logging.getLogger(config.APP_NAME + ".cache")


@dataclass
class CacheEntry:
    """Represents a single cache entry with TTL support."""
    
    status: StreamStatus
    timestamp: float
    ttl_seconds: int
    
    def is_expired(self) -> bool:
        """Check if this cache entry has expired."""
        return time.time() - self.timestamp > self.ttl_seconds
    
    def time_until_expiry(self) -> float:
        """Get seconds until this entry expires (negative if already expired)."""
        return (self.timestamp + self.ttl_seconds) - time.time()


class StreamStatusCache:
    """
    Thread-safe cache for stream status information with TTL support.
    
    This cache stores stream liveness status to avoid redundant streamlink calls
    within a configurable time window.
    """
    
    def __init__(self, default_ttl_seconds: int = 300):
        """
        Initialize the cache.
        
        Args:
            default_ttl_seconds: Default TTL for cache entries in seconds (default: 5 minutes)
        """
        self._cache: Dict[str, CacheEntry] = {}
        self._lock = Lock()
        self._default_ttl = default_ttl_seconds
        logger.debug(f"Initialized StreamStatusCache with default TTL: {default_ttl_seconds}s")
    
    def get(self, url: str) -> Optional[StreamStatus]:
        """
        Get cached stream status for a URL.
        
        Args:
            url: The stream URL to look up
            
        Returns:
            StreamStatus if cached and not expired, None otherwise
        """
        with self._lock:
            entry = self._cache.get(url)
            if entry is None:
                logger.debug(f"Cache miss for URL: {url}")
                return None
            
            if entry.is_expired():
                logger.debug(f"Cache entry expired for URL: {url}")
                del self._cache[url]
                return None
            
            logger.debug(f"Cache hit for URL: {url}, status: {entry.status.value}")
            return entry.status
    
    def put(self, url: str, status: StreamStatus, ttl_seconds: Optional[int] = None) -> None:
        """
        Store stream status in cache.
        
        Args:
            url: The stream URL
            status: The stream status to cache
            ttl_seconds: TTL for this entry (uses default if None)
        """
        ttl = ttl_seconds if ttl_seconds is not None else self._default_ttl
        
        with self._lock:
            entry = CacheEntry(
                status=status,
                timestamp=time.time(),
                ttl_seconds=ttl
            )
            self._cache[url] = entry
            logger.debug(f"Cached status for URL: {url}, status: {status.value}, TTL: {ttl}s")
    
    def invalidate(self, url: str) -> bool:
        """
        Remove a specific URL from cache.
        
        Args:
            url: The stream URL to invalidate
            
        Returns:
            True if entry was removed, False if not found
        """
        with self._lock:
            if url in self._cache:
                del self._cache[url]
                logger.debug(f"Invalidated cache entry for URL: {url}")
                return True
            return False
    
    def invalidate_pattern(self, pattern: str) -> int:
        """
        Invalidate all cache entries where URL contains the pattern.
        
        Args:
            pattern: String pattern to match in URLs
            
        Returns:
            Number of entries invalidated
        """
        with self._lock:
            urls_to_remove = [url for url in self._cache.keys() if pattern in url]
            for url in urls_to_remove:
                del self._cache[url]
            
            if urls_to_remove:
                logger.debug(f"Invalidated {len(urls_to_remove)} cache entries matching pattern: {pattern}")
            
            return len(urls_to_remove)
    
    def clear(self) -> int:
        """
        Clear all cache entries.
        
        Returns:
            Number of entries cleared
        """
        with self._lock:
            count = len(self._cache)
            self._cache.clear()
            logger.info(f"Cleared {count} cache entries")
            return count
    
    def cleanup_expired(self) -> int:
        """
        Remove all expired entries from cache.
        
        Returns:
            Number of expired entries removed
        """
        with self._lock:
            expired_urls = [
                url for url, entry in self._cache.items() 
                if entry.is_expired()
            ]
            
            for url in expired_urls:
                del self._cache[url]
            
            if expired_urls:
                logger.debug(f"Cleaned up {len(expired_urls)} expired cache entries")
            
            return len(expired_urls)
    
    def get_stats(self) -> Dict[str, int]:
        """
        Get cache statistics.
        
        Returns:
            Dictionary with cache statistics
        """
        with self._lock:
            total_entries = len(self._cache)
            expired_entries = sum(1 for entry in self._cache.values() if entry.is_expired())
            active_entries = total_entries - expired_entries
            
            return {
                "total_entries": total_entries,
                "active_entries": active_entries,
                "expired_entries": expired_entries
            }
    
    def get_cache_info(self) -> Dict[str, any]:
        """
        Get detailed cache information for debugging.
        
        Returns:
            Dictionary with detailed cache information
        """
        with self._lock:
            entries_info = []
            for url, entry in self._cache.items():
                entries_info.append({
                    "url": url,
                    "status": entry.status.value,
                    "age_seconds": time.time() - entry.timestamp,
                    "ttl_seconds": entry.ttl_seconds,
                    "time_until_expiry": entry.time_until_expiry(),
                    "is_expired": entry.is_expired()
                })
            
            return {
                "default_ttl": self._default_ttl,
                "entries": entries_info,
                "stats": self.get_stats()
            }


# Global cache instance
_global_cache: Optional[StreamStatusCache] = None
_cache_lock = Lock()


def get_cache() -> StreamStatusCache:
    """
    Get the global cache instance, creating it if necessary.
    
    Returns:
        The global StreamStatusCache instance
    """
    global _global_cache
    
    with _cache_lock:
        if _global_cache is None:
            # Get TTL from config, with fallback to 5 minutes
            ttl = config.get_cache_ttl_seconds() if hasattr(config, 'get_cache_ttl_seconds') else 300
            _global_cache = StreamStatusCache(default_ttl_seconds=ttl)
            logger.info(f"Created global cache instance with TTL: {ttl}s")
        
        return _global_cache


def reset_cache() -> None:
    """Reset the global cache instance (mainly for testing)."""
    global _global_cache
    
    with _cache_lock:
        if _global_cache:
            _global_cache.clear()
        _global_cache = None
        logger.info("Reset global cache instance")
